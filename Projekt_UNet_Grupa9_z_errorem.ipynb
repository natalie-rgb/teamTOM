{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projekt_UNet_Grupa9_z_errorem",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natalie-rgb/teamTOM/blob/master/Projekt_UNet_Grupa9_z_errorem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sTvUuC0b54c",
        "colab_type": "code",
        "outputId": "0970aa5a-1354-440d-d317-b98bc29ae9f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        }
      },
      "source": [
        "! curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
        "! sudo apt-get install git-lfs\n",
        "! git lfs install\n",
        "! git clone https://github.com/neheller/kits19.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detected operating system as Ubuntu/bionic.\n",
            "Checking for curl...\n",
            "Detected curl...\n",
            "Checking for gpg...\n",
            "Detected gpg...\n",
            "Running apt-get update... done.\n",
            "Installing apt-transport-https... done.\n",
            "Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n",
            "Importing packagecloud gpg key... done.\n",
            "Running apt-get update... done.\n",
            "\n",
            "The repository is setup! You can now install packages.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  git-lfs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 6,877 kB of archives.\n",
            "After this operation, 16.4 MB of additional disk space will be used.\n",
            "Get:1 https://packagecloud.io/github/git-lfs/ubuntu bionic/main amd64 git-lfs amd64 2.11.0 [6,877 kB]\n",
            "Fetched 6,877 kB in 1s (7,878 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package git-lfs.\n",
            "(Reading database ... 144332 files and directories currently installed.)\n",
            "Preparing to unpack .../git-lfs_2.11.0_amd64.deb ...\n",
            "Unpacking git-lfs (2.11.0) ...\n",
            "Setting up git-lfs (2.11.0) ...\n",
            "Git LFS initialized.\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Git LFS initialized.\n",
            "Cloning into 'kits19'...\n",
            "remote: Enumerating objects: 954, done.\u001b[K\n",
            "remote: Counting objects: 100% (954/954), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 991 (delta 433), reused 927 (delta 408), pack-reused 37\u001b[K\n",
            "Receiving objects: 100% (991/991), 29.70 MiB | 23.45 MiB/s, done.\n",
            "Resolving deltas: 100% (451/451), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz_vlNAhcBJy",
        "colab_type": "code",
        "outputId": "23ad8d6b-aa8f-4e26-d8e3-edea307c4247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        }
      },
      "source": [
        "%cd kits19\n",
        "!pip3 install -r /content/kits19/requirements.txt\n",
        "! python -m starter_code.get_imaging"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/kits19\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r /content/kits19/requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.6/dist-packages (from -r /content/kits19/requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from -r /content/kits19/requirements.txt (line 3)) (2.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from -r /content/kits19/requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r /content/kits19/requirements.txt (line 5)) (4.41.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio->-r /content/kits19/requirements.txt (line 3)) (7.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->-r /content/kits19/requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->-r /content/kits19/requirements.txt (line 4)) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->-r /content/kits19/requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->-r /content/kits19/requirements.txt (line 4)) (2020.4.5.1)\n",
            "300 cases to download...\n",
            "Download 1/300: \n",
            "case_00000: 100% 225959/225960 [00:14<00:00, 15220.02KB/s]\n",
            "Download 2/300: \n",
            "case_00001: 100% 276387/276388 [00:14<00:00, 19314.36KB/s]\n",
            "Download 3/300: \n",
            "case_00002: 100% 101967/101968 [00:07<00:00, 13991.12KB/s]\n",
            "Download 4/300: \n",
            "case_00003: 100% 118681/118682 [00:08<00:00, 14365.17KB/s]\n",
            "Download 5/300: \n",
            "case_00004: 100% 25269/25270 [00:02<00:00, 10317.39KB/s]\n",
            "Download 6/300: \n",
            "case_00005: 100% 313477/313478 [00:20<00:00, 15364.17KB/s]\n",
            "Download 7/300: \n",
            "case_00006: 100% 78010/78011 [00:05<00:00, 13409.84KB/s]\n",
            "Download 8/300: \n",
            "case_00007:   7% 1806/25827 [00:00<00:11, 2015.66KB/s]\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jyxe7G3ecIy9",
        "colab_type": "code",
        "outputId": "0d02a42c-d659-4658-8d9c-dd9343d7e45f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/kits19/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/kits19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFC04RytMqWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "train_path = \"/content/kits19/data/case_00000\"\n",
        "cases =  next(os.walk(train_path))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGhzBtorAeDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_filename = os.path.join(train_path, cases[2][-1])\n",
        "gt_filename = os.path.join(train_path, cases[2][0]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiTuOAX8KFWS",
        "colab_type": "code",
        "outputId": "26dac488-fdfa-489b-8cf4-899d0dd6af0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gt_filename\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/kits19/data/case_00000/segmentation.nii.gz'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2OCcivdkrLR",
        "colab_type": "code",
        "outputId": "f7f7339c-ace2-4200-8740-1dde7fa3d0da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "!pip install medicaltorch"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: medicaltorch in /usr/local/lib/python3.6/dist-packages (0.2)\n",
            "Requirement already satisfied: tqdm>=4.23.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.18.5)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.5.0+cu101)\n",
            "Requirement already satisfied: nibabel>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (3.0.2)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (0.6.0+cu101)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.0->medicaltorch) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEmgPsHeAPIv",
        "colab_type": "code",
        "outputId": "d602983d-2678-44e2-b0c4-7c82ec7168d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "from medicaltorch import datasets as mt_datasets\n",
        "from skimage import color\n",
        "pair = mt_datasets.SegmentationPair2D(input_filename, gt_filename) \n",
        "slice_pair = pair.get_pair_slice(175)\n",
        "input_slice = slice_pair[\"input\"]\n",
        "gt_slice = slice_pair[\"gt\"]\n",
        "\n",
        "img = input_slice\n",
        "label = gt_slice\n",
        "plt.imshow(label, cmap = 'gray')\n",
        "plt.show()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOlhfpUpBIAZ",
        "colab_type": "code",
        "outputId": "8380dcce-b8d2-4f9d-88c7-18fcb3e61b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "np.unique(label)  #ile wyróżnia nam klas"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rrKiP4CURtG",
        "colab_type": "code",
        "outputId": "ad528962-82e0-4280-8b43-638021d00b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler, Adam, SGD\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from medicaltorch import models as mt_models\n",
        "from keras.utils import to_categorical as cat\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc2HAc0GURpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "train_path = \"/content/kits19/data/\"\n",
        "cases =  next(os.walk(train_path))\n",
        "file_name = cases[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQcr4haCAUU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = mt_models.Unet(drop_rate=0.4, bn_momentum=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCti5YV7AURm",
        "colab_type": "code",
        "outputId": "25b570ad-c742-40fa-f046-6d057bac5d7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unet(\n",
              "  (conv1): DownConv(\n",
              "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv1_drop): Dropout2d(p=0.4, inplace=False)\n",
              "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2_drop): Dropout2d(p=0.4, inplace=False)\n",
              "  )\n",
              "  (mp1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): DownConv(\n",
              "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv1_drop): Dropout2d(p=0.4, inplace=False)\n",
              "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2_drop): Dropout2d(p=0.4, inplace=False)\n",
              "  )\n",
              "  (mp2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): DownConv(\n",
              "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv1_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv1_drop): Dropout2d(p=0.4, inplace=False)\n",
              "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2_drop): Dropout2d(p=0.4, inplace=False)\n",
              "  )\n",
              "  (mp3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv4): DownConv(\n",
              "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv1_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv1_drop): Dropout2d(p=0.4, inplace=False)\n",
              "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2_drop): Dropout2d(p=0.4, inplace=False)\n",
              "  )\n",
              "  (up1): UpConv(\n",
              "    (up1): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "    (downconv): DownConv(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (conv1_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1_drop): Dropout2d(p=0.4, inplace=False)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (conv2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2_drop): Dropout2d(p=0.4, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (up2): UpConv(\n",
              "    (up1): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "    (downconv): DownConv(\n",
              "      (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (conv1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1_drop): Dropout2d(p=0.4, inplace=False)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (conv2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2_drop): Dropout2d(p=0.4, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (up3): UpConv(\n",
              "    (up1): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "    (downconv): DownConv(\n",
              "      (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1_drop): Dropout2d(p=0.4, inplace=False)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2_drop): Dropout2d(p=0.4, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (conv9): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP8Gm9aDAUL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform(img, lbl):\n",
        "    img = img.astype(float)\n",
        "    lbl = lbl.astype(float)\n",
        "    img -= np.mean(img)\n",
        "    img /= 255.0\n",
        "    img = np.resize(img, (224, 224))  \n",
        "    img = torch.from_numpy(img).unsqueeze_(0)\n",
        "    print('Img shape:', img.shape)\n",
        "    lbl = np.resize(lbl, (224, 224))  \n",
        "    lbl = torch.from_numpy(lbl).unsqueeze_(0)\n",
        "    print('Label shape:', lbl.shape)\n",
        "    \n",
        "    return img, lbl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5bazMsFAUDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        global image\n",
        "        global classes\n",
        "        cases = file_name[idx]\n",
        "        file_path = train_path + cases +'/'\n",
        "        content = next(os.walk(file_path))\n",
        "        if 'segmentation.nii.gz' not in content[2]:\n",
        "          pass\n",
        "        else:\n",
        "          input_filename = file_path + content[2][-1]\n",
        "          gt_filename = file_path + content[2][0]\n",
        "          pair = mt_datasets.SegmentationPair2D(input_filename, gt_filename)\n",
        "          slice_pair = pair.get_pair_slice(175)\n",
        "          image = slice_pair[\"input\"]\n",
        "          classes = slice_pair[\"gt\"]\n",
        "          image,classes = transform(image, classes)\n",
        "          \n",
        "\n",
        "        return image, classes  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYDWwYrIAT38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TrainDataset(file_name) \n",
        "train_loader = DataLoader(train_dataset, batch_size=2, num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JftbdIbUPN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgDgX5_wGIH4",
        "colab_type": "code",
        "outputId": "42bb7be1-9643-48e5-c030-2c80e8c7ca29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "\n",
        "for data, label in train_loader:\n",
        "    print (\"list data:\")\n",
        "    print (data)\n",
        "    print (label)\n",
        "    break"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Img shape: torch.Size([1, 224, 224])\n",
            "Label shape: torch.Size([1, 224, 224])\n",
            "Img shape: torch.Size([1, 224, 224])\n",
            "Label shape: torch.Size([1, 224, 224])\n",
            "list data:\n",
            "tensor([[[[-1.2895e-04, -1.2895e-04, -1.2895e-04,  ..., -1.2895e-04,\n",
            "           -1.2895e-04, -1.2895e-04],\n",
            "          [-1.2895e-04, -1.2895e-04, -1.2895e-04,  ..., -1.2895e-04,\n",
            "           -1.2895e-04, -1.2895e-04],\n",
            "          [-1.2895e-04, -1.2895e-04, -1.2895e-04,  ..., -1.2895e-04,\n",
            "           -1.2895e-04, -1.2895e-04],\n",
            "          ...,\n",
            "          [-1.2895e-04, -1.2895e-04, -1.2895e-04,  ..., -1.2895e-04,\n",
            "           -1.2895e-04, -1.2895e-04],\n",
            "          [-1.2895e-04, -1.2895e-04, -1.2895e-04,  ..., -1.2895e-04,\n",
            "           -1.2895e-04, -1.2895e-04],\n",
            "          [-1.2895e-04, -1.2895e-04, -1.2895e-04,  ..., -1.2895e-04,\n",
            "           -1.2895e-04, -1.2895e-04]]],\n",
            "\n",
            "\n",
            "        [[[-7.4417e-05, -7.4417e-05, -7.4417e-05,  ..., -7.4417e-05,\n",
            "           -7.4417e-05, -7.4417e-05],\n",
            "          [-7.4417e-05, -7.4417e-05, -7.4417e-05,  ..., -7.4417e-05,\n",
            "           -7.4417e-05, -7.4417e-05],\n",
            "          [-7.4417e-05, -7.4417e-05, -7.4417e-05,  ..., -7.4417e-05,\n",
            "           -7.4417e-05, -7.4417e-05],\n",
            "          ...,\n",
            "          [-7.4417e-05, -7.4417e-05, -7.4417e-05,  ..., -7.4417e-05,\n",
            "           -7.4417e-05, -7.4417e-05],\n",
            "          [-7.4417e-05, -7.4417e-05, -7.4417e-05,  ..., -7.4417e-05,\n",
            "           -7.4417e-05, -7.4417e-05],\n",
            "          [-7.4417e-05, -7.4417e-05, -7.4417e-05,  ..., -7.4417e-05,\n",
            "           -7.4417e-05, -7.4417e-05]]]], dtype=torch.float64)\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmYn1maBfDVt",
        "colab_type": "code",
        "outputId": "47796dfe-37de-4511-8471-1772cc1373d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        }
      },
      "source": [
        "\n",
        "train_loss_total = 0 \n",
        "num_epochs = 4 \n",
        "model.to(device) \n",
        "\n",
        "for epoch in range(num_epochs): \n",
        "  print('Epoch has started') \n",
        "  for data, label in iter(train_loader): \n",
        "    data.to(device) \n",
        "    label.to(device) \n",
        "    print('step 1 check')\n",
        "    outputs = model(data) \n",
        "    loss = criterion(outputs, label) \n",
        "    loss.backward() \n",
        "    print('step 2 check')\n",
        "    optimizer.step() \n",
        "  train_loss_total += loss.item() \n",
        "  train_loss_total_avg = train_loss_total / len(train_loader) \n",
        "  print('epoch number ', epoch, \"\t\t\t\t\t\",'Error term', train_loss_total_avg)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch has started\n",
            "Img shape: torch.Size([1, 224, 224])\n",
            "Label shape: torch.Size([1, 224, 224])\n",
            "Img shape: torch.Size([1, 224, 224])\n",
            "Label shape: torch.Size([1, 224, 224])\n",
            "step 1 check\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-d13f76aa277e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'step 1 check'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/medicaltorch/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmp1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/medicaltorch/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    344\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    345\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 346\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward"
          ]
        }
      ]
    }
  ]
}